# 自我监督的知识蒸馏技术 [paper](https://arxiv.org/pdf/2006.09785.pdf)

## Abstract

现实世界中包含大量的对象类，无法一次学习所有对象类。很少有镜头学习是一种有前途的学习范例，因为它具有仅需几个样本即可快速学习无序分布的能力。最近的工作[7,41]表明，仅学习良好的特征嵌入可以胜过仅需少量学习的更复杂的元学习和度量学习算法。在本文中，我们提出了一种简单的方法来提高深度神经网络对少量镜头学习任务的表示能力。我们遵循两个阶段的学习过程：首先，我们训练神经网络以最大化特征嵌入的熵，从而使用自监督辅助损失创建最佳输出流形。在第二阶段，我们通过将自我监督的双胞胎放到一起来最小化特征嵌入的熵，同时用学生-教师蒸馏约束流形。我们的实验表明，即使在第一阶段，自我监督也能胜过当前的最新方法，而第二阶段的蒸馏过程可以进一步提高收益。

> [7]G. S. Dhillon, P. Chaudhari, A. Ravichandran, and S. Soatto. A baseline for few-shot image classification.InInternational Conference on Learning Representations, 2020.
> 少量镜头分类的基准

> [41]Y. Tian, Y. Wang, D. Krishnan, J. B. Tenenbaum, and P. Isola. Rethinking few-shot image classification: agood embedding is all you need?arXiv preprint arXiv:2003.11539, 2020.
> 重新考虑少量拍摄的图像分类：只需要一个好的嵌入

## Introduction

现代深度学习算法通常需要大量带注释的数据，获取这些数据通常很费力且昂贵[2,19]。受人类只能从很少的例子中学习的事实启发，少拍学习（FSL）提供了一种有前途的机器学习范例。FSL的目标是开发仅使用少数带注释的样本（通常为1-5）即可推广到新概念的模型。由于数据匮乏和监督有限，FSL仍然是一个具有挑战性的问题

现有的工作主要是通过元学习[11,23,18,35,3,21,33]来使FSL适应新任务，或者通过度量学习强制执行最大化利润约束[20,40,42,37]。这样做时，这些FSL方法在寻求实现类间可分辨性时忽略了类内多样性的重要性。在这项工作中，我们主张采用等变表示，而不是学习在班级变更中不变的表示。我们的主要直觉是，希望输入域中的主要变换反映在它们的相应输出中，以确保输出空间的多样性。通过以等变方式忠实地反映这些变化，我们寻求学习对象类的真实自然流形

我们为FSL提出了一种两阶段的自我监督知识蒸馏（SKD）方法。尽管仅提供了几张标记的示例，但我们显示可以从有限的数据中挖掘辅助自我监督学习（SSL）信号，并有效地利用它们来学习真正的输出空间每个类别的流形。为此，我们采取了与以前的工作相反的方向，前一个工作学习了将增加的输入映射到相同预测的不变表示。为了提高模型的通用性，我们首先学习一个生成零（Gen-0）模型，该模型的输出预测与输入转换等价，从而避免了预测空间的过度拟合和确保其异构性。例如，当在学习的第一阶段学习对对象进行分类时，基于自我监督的学习目标可确保输出对数足够丰富，以编码应用于输入图像的旋转量（大概意思应该是取足够多的类中心点，方便以后聚类）

​		训练了零代网络以估计最佳输出流形后，我们通过将学习的模型视为教师网络并使用教师的输出来训练学生模型来执行知识提炼。与第一阶段不同，我们现在认为，增加样本和原始输入会导致类似的预测，以增强类别间的区别。因此，知识提取机制指导一代（Gen-1）模型开发两个直观的属性。首先，输出类流形足够多样化以保留输入中的主要转换，从而避免过拟合和改进泛化;其次，输出空间中的学习关系进行编码类之间的自然联系（例如，两个相似的类）应该具有相关的预测，而不是在一个热编码的地面真相中考虑的完全独立的类。因此，通过对类间关系进行编码并保持类内多样性来忠实地表示输出空间，我们的方法可以学习FSL的改进表示形式

（在0阶段结束之后，增加样本来增强类别间的区别。这样的做的原因是，因为中心点足够多，刚进入的样本特征很快就能找到靠近的中心点，这样就不会过拟合了，同时中心点较多，也保持模型的泛化能力。第二个原因就是作者认为one-hot的方式不好，类似标签平滑这种方式会更好一些。）

以下是这项工作的主要贡献（概述见图1）。

- 与使用SSL作为辅助任务的现有作品不同，我们展示了SSL通过简单的体系结构修改即可在预测空间中加强多样性约束的优势

- 一个双阶段训练方案，该方案首先估计最佳输出歧管，然后最小化原始增加的配对距离，同时使用蒸馏损失将原始样本锚定到学习的歧管。
- 对四个流行的基准数据集进行了广泛的评估，并对FSL任务进行了重大改进。

## Related work

自我监督学习（SSL）：这种学习形式定义了辅助学习任务，这些任务可以增强模型的学习能力，而无需任何其他注释工作。通常，这些替代任务需要更高层次的理解，从而迫使学习代理在解决辅助任务时学习有用的表示。现有SSL技术的主要区别在于从数据获取监管信号的方式。例如，[15]通过预测应用于输入图像的旋转量来学习有用的表示。Doerschet等人[8]训练CNN来预测一对随机采样的图像块的相对位置。在[26]中，这个想法被进一步扩展以预测多个图像补丁的排列。另外，图像着色和对象计数被用作借口任务，以改善表示学习[45,27]。Zhaiet等人[44]提出一种在半监督环境中使用SSL方法的情况，其中可以使用一些标记的示例和许多未标记的示例。与这些作品不同，我们的方法是使用自我监督在分类空间中施加其他约束。接近我们的工作的是寻求学习图像变换和增强不变表示的一组方法[9,4,5]。相反，我们的方法则恰好相反：我们试图学习等变表示，以便仅通过几个示例就可以了解对象类的真实自然流形。

​		很少学习（FSL）：从度量学习到元学习方法，FSL方面已经进行了一些努力。度量学习方法通常会学习一个度量空间，在该空间中，支持集可以轻松地与查询集匹配。例如，科切特[20]在支持集的帮助下，使用暹罗网络学习相似度指标对未知类进行分类。Sunget等人[40]使用关系模块来学习支持集和查询图像之间的关系。Matchingnetworks [42]利用注意力和记忆来学习一个将支持集与查询图像匹配的网络。另外，[37]将均值嵌入指定为原型，并将与查询集中其余样本的距离最小化。相比之下，我们仅使用图像的增强对来更靠近它们的嵌入，同时在输出空间中保留它们各自的距离

​		另一类方法使用元学习来利用从过去任务中获得的知识来学习新任务。Finnet等人[11]提出了一个流行的与模型无关的元学习（MAML）框架，该框架找到了更好的初始化权重，这些权重可以快速应用于给定的支持集。在[11]，[23,12]的基础上，使用元学习预处理对梯度流进行重定向，以实现更好的收敛性。除这些工作外，LEO（潜在嵌入优化）[35]将网络权重转换为一个较低维的潜在嵌入空间，并应用MAML算法扩展到更大的网络。MetaOptNet [21]使用支持向量机将元学习建模为凸优化问题，该问题使用二次规划解决

（FSL主要是2个类别，创建一个度量空间，类似一个字典，查询就能找到类似。另外一种就是让梯度收敛更快，让梯度快读的下降到理想的位置。先抽取模型的权重，然后提纯到更高的维度，用提纯后的模型指导新模型的产生。）

​		最近的一些著作将元学习的成功归功于其强大的特征表示能力，而不是元学习本身[31]。其他人[7,41]通过学习强大的嵌入展示了简单基线的有效性。这项工作是朝着同一方向努力的，并提出了一种新颖的自我监督知识蒸馏方法，该方法可以学习FSL的有效特征表示。与我们的工作最接近的是吉达里塞特等人[13]，他们使用自我监督来增强少数镜头分类。然而，[13]简单地将自我监督作为单次训练的辅助损失，而我们使用它来塑造和约束学习流形。在架构方面，我们使用顺序自我监督层，而[13]则采用并行设计。尽管[13]没有多代，但通过使用蒸馏限制嵌入空间并使旋转对的嵌入更接近其原始嵌入，我们进一步改进了第二代的表示。

![QQ浏览器截图20200623112904](C:\Users\Administrator\Desktop\day0623\1.png)

图1：自我监督的知识传播分两个阶段进行。在第0代中，自我监督用于估计与输入转换等价的真实预测流形。具体来说，我们强制执行该模型以仅使用输出logit来预测输入旋转量。在第1代中，我们强制原始样本输出与第0代（虚线）相同，同时使用增强的版本来减小其距离以增强可分辨性。

## 3. Our Apporach

​		拟议的SKD使用了两阶段的培训流程；零代（Gen-0）和Generationone（Gen-1）。Gen-0利用自我监督来学习更广泛的分类流形，其中学习的嵌入与旋转等价（或其他数据转换）。后来，在第1代期间，我们使用第0代模型作为老师，并使用原始（非旋转）图像作为锚点来保留学习的流形，同时使用图像的旋转版本将嵌入空间中的类内距离减少到学习强大而有区别的特征表示。

**3.1Setting**

假设神经网络包含特征嵌入参数Φ和分类权重Θ。任何输入图像x都可以通过函数fΦ：x→v映射到特征向量v∈Rd，因此，特征v通过另一个函数fΘ：特征v→p映射到 logitsp∈Rc，其中c表示输出类别的数量。因此，传统上将Fis定义为这些函数的组合，F =fΦΦfΘ。在这项工作中，我们引入了另一个由parameter参数化的函数fΨ，使得fΨ：p→q将logitsp映射到用于自我监督任务（例如轮换分类）的logitsq∈Rs的第二集合

原文：

Lets assume a neural networkFcontains feature embedding parametersΦ, and classification weightsΘ.   Any input imagexcan be mapped to a feature vectorv∈Rdby a functionfΦ:x→v.Consequently, featuresvare mapped to logitsp∈Rcby another functionfΘ:v→p, wherecdenotes the number of output classes. Hence, conventionallyFis defined as a composition of thesefunctions,F=fΦ◦fΘ.  In this work, we introduce another functionfΨ, parameterized byΨ, suchthat,fΨ:p→q, which maps logitspto a secondary set of logitsq∈Rsfor self-supervised task(e.g., rotation classification). For each inputx, we automatically obtain labelsr∈{1,...,s}for theself-supervision task. Therefore, the complete network can be represented asFΦ,Θ,Ψ=fΨ◦fΘ◦fΦ

大概意思就：输入1通过函数fx0映射得到输出1。输入2通过fx0得到输出2。fis就是2者的组合。现在我们多添加一个函数fx1，将输入输出关联起来。这样完整的网络就是这3这的组合了

我们考虑一个数据集Dwithnimage-label对{xi，yi}nwhereyi∈{1，...，c}。在评估过程中，我们像经典的少拍学习文学中那样对情节进行采样。情节包含，DupppandDquery。在单拍设置中，D重复每个n类的样本数

**3.2Generation Zero**  第0代

在第一阶段（即第0代）中，从数据集D中随机采样一个minibatchB = {x，y}，该数据集具有多个图像标签对，例如x = {xi} m，y = {yi} m。我们首先拍摄图像x，然后应用变换函数T（·）创建x的增强副本。为了简洁起见，此处将T（·）视为旋转变换，但是任何其他合适的变换都可以如我们在实验中所示（4.2节）。分别应用90、180和270度tox旋转，分别创建x90，x180和x270。然后我们将图像的所有增强版本组合为一个张量̂x = {x，x90，x180，x270}，其对应的类别标签为̂y∈R4×m。另外，还为旋转方向创建了一个热编码标签̂r = {ri∈Rs} 4×m，其中，由于我们的自我监督任务中的四个旋转方向，其中= 4

首先，我们传递̂xthroughfΦ，得到特征̂v∈Rd×（4×m）。然后，将特征通过fΘ，得到对应的logitŝp∈Rc×（4×m），最后，对数通过fΨ，得到旋转logitŝq∈Rs×（4×m）

我们使用两个损失函数来优化Gen-0中的模型：（a）预测对数之间的绝对交叉熵损失Lce跨真实标签y，以及（b）旋转对数q和旋转标签之间的自监督损失Ls。注意，自我监督损失只是二进制交叉熵损失。将这两个损失项与权重系数α相结合，得出最终损失

训练Gen-0模型的整个过程可以描述为以下优化问题，

上面的目标确保输出logit具有足够的代表性，可以封装有关输入变换的信息，从而成功地预测应用于输入的旋转量。这种行为使我们能够在输出空间中保持多样性，并忠实地估计每个对象类别的自然数据流形。

![](C:\Users\Administrator\Desktop\day0623\2.png)

图2：SKD：Generation Zero的总体训练过程使用图像的多个旋转版本来训练神经网络，以预测类别以及旋转角度。然后在第一代中，我们使用图像的原始版本作为定位点，以保留流形，同时将旋转版本的对数移近，以提高网络的判别能力

**3.3 Generation One**

用交叉熵和自我监督损失函数训练Gen-0模型后，我们将采用训练模型的两个克隆：教师模型$F^t$和学生模型$F^s$。教师模型的权重被冻结，仅用于推断。同样，我们对最小批次BfromD采样并生成atwin ̄x∈̂x \ xfromx。在这种情况下，双胞胎x只是x（例如，x180）的旋转形式。在Gen-1训练期间，x是用作锚点以约束对分类流形的任何更改。这是由师生网络之间的知识流失[17]造成的。同时，使用辅助2损失将x和̄x的嵌入结合在一起，以增强特征可分辨性，同时保留原始输出歧管。

具体来说，我们首先通过x穿过教师网络$F^t$ =$f^t_{Φ,Θ}$◦$f^t_Ψ$并获得其logits $p^t$。然后，x,$x^-$ 通过传递 $F^S$ 去得到相应的logits的$P^S$ 和 $P-^S$ 

![](C:\Users\Administrator\Desktop\day0623\3.png)

我们使用Kullback-Leibler（KL）之间的差异度量$p^t$ = {$p^t_i$} 和 $p^S$ = {$p^s_i$} 用于知识升华,和应用一个 l2 损失在 $p^S$ 个 $p-^S$ 以实现更好的可分辨性

![](C:\Users\Administrator\Desktop\day0623\4.png)

其中，σ是softmax函数，而T是用于软化输出分布的温度参数。最后，我们用系数β组合这两个损耗项，如下

![](C:\Users\Administrator\Desktop\day0623\5.png)

整个第一代培训过程可以说是以下优化问题

![](C:\Users\Administrator\Desktop\day0623\6.png)

请注意，在我们的设置中，有必要将旋转分类头顺序添加到分类层，这与之前的工作[13,6,39]不同，后者将旋转分类头直接连接到要素嵌入层之后。这是因为，在第0代期间，我们鼓励倒数第二层对有关图像类别及其旋转的信息进行编码（从而保留输出空间的多样性），然后在第1代中，我们使旋转对的对数更加接近（改善歧视）。如果旋转头直接连接到特征嵌入层，或者对特征嵌入进行蒸馏，则这些好处是不可能的

![](C:\Users\Administrator\Desktop\day0623\7.png)

（程序流程：遍历每个样本，旋转增强，新x是由90，180，270，0组合而成，y就是复制4个y组合而成。然后编号0，1，2，3，给r，经过resnet得到v，v进过正常分类得p，p抽象分类得q。然后计算损失，ce是正常损失，ss是自我监督的损失，然后按损失的情况进行梯度下降。将得到的网络复制2次。一个作为教师网络，一个作为学生网络，遍历训练集，学生网络的输入增强旋转180，未处理的图片经过教师网络得到pt，然后未处理的图片和旋转后的图片进入学生网络得到ps和p_s。然后就是计算损失包含蒸馏损失和L2正则的损失，然后梯度下降。得到学生网络。）



**3.4 Evaluation**

在评估过程中，数据集的保留部分用于对任务进行采样。这包括一个支持集和一个查询集{$D_{supp}$，$D_{query}$}。$D_{supp}$有图像标签对{$x_{supp}$，$y_{supp}$}，而$D_{query}$包含图像张量查询。将两个$x_{supp}$和$x_{query}$馈入最终训练的$f^s_Φ$模型，分别获得特征嵌入$v_{supp}$和$v_{query}$。我们使用一个简单的逻辑回归分类器[41,3]将标签从支持集映射到查询集。嵌入被标准化为一个单位球[41]。我们随机抽样600个任务，并以95％的置信区间报告均值分类准确性。与流行的元学习算法（例如[11,23]）不同，我们不需要针对n阶，k镜头分类的不同值训练多个模型。由于在我们的案例中，分类与特征学习没有关系，因此可以使用相同的模型来评估n和k在 FSL的任何值

#### **4 Experiments and Results**

我们在四个基准的少拍学习数据集（即mini-ImageNet [42]，tieredImageNet [34]，CIFAR-FS [3]和FC100 [28]）上全面比较了我们的方法。此外，我们提供了广泛的消融研究，以研究不同成分的个体贡献（第4.2节）

实现细节：为了与以前的方法[41,24,28,21]一致，我们在实验中使用ResNet-12作为主干。骨干架构包含4个残差块，如[41,33,21]中的64,160,320,640个过滤器，每个残块具有3×3卷积。在前三个块之后应用A2×2max池化操作，在最后一个块之后应用全局平均池化。此外，在最终分类层之后添加一个神经元全连接层。

我们使用SGD，初始学习率为0.05，动量为0.9，权重衰减为5e−4。在第60个时期之后，学习率降低了0.1倍。CIFAR-FS上的Gen-0和Gen-1模型训练了65个时期，而其余模型仅训练了8个时期。与以前的方法[11,41,35]一致，在训练过程中将随机裁剪，颜色抖动和随机水平翻转应用于数据增强。此外，超参数α，β在验证集上进行了调整，我们使用与[41]中相同的4.0值作为蒸馏过程中的温度系数。

数据集：我们在四个广泛使用的FSL基准上评估了我们的方法。这些包括两个数据集，它们是ImageNet的子集，即miniImageNet [42]和tieredImageNet [34]，另外两个是CIFAR100的子集，即CIFAR-FS [3]和FC100 [28]。对于miniImageNet [42]，我们使用[32]中提出的拆分方法，分为64、16和20个类，用于训练，验证和测试。ThetieredImageNet [34]包含608个类别，这些类别在语义上分为34个高级类别，这些类别又分为20、6和8进行训练，验证和测试拆分，从而使拆分更加多样化。CIFAR-FS [3]包含100个类别的随机划分，分为64、16和20个类别，用于训练，验证和测试，而FC100 [28]使用类似于tieredImageNet的划分，从而使划分更加多样化。FC100分别提供60、20、20个培训，验证和测试课程

![](C:\Users\Administrator\Desktop\day0623\8.png)

表1：在miniImageNet [42]和tieredImageNet [34]数据集上的FSL结果，其平均准确度和置信区间为95％。†通过训练火车+ val集获得的结果。表是[41]的扩展版本。

![](C:\Users\Administrator\Desktop\day0623\9.png)

表2：CIFAR-FS [3]和FC100 [28]数据集上的FSL，具有平均准确度和95％的置信区间。表是[41]的扩展版本

**4.1 Few-shot learning results**

我们在表1和表2中显示的结果表明，在所有四个数据集上，所提出的方法始终优于当前方法。甚至，我们的Gen-0仅比目前的最新技术（SOTA）表现要好得多。例如，在5次1次射击和5次5次射击任务中，SKD Gen-0模型在miniImageNet上的SOTA性能要高出约1％。在其他数据集上也可以观察到相同的结果。与简单的RFS [41]（类似于我们的Gen-0）相比，SKD显示5次1次射击的学习能力提高了3.91％，5次5次射击的学习能力提高了3.51％。在其他评估数据集上，可以观察到相同的趋势，其收益比简单RFS稳定2-3％。这是由于新颖的自我监督功能使SKD能够学习多样化和通用的嵌入空间

Gen-1结合了知识提炼，并且比Gen-0更加有效。在OnminiImageNet上，我们在5次1次和5次5次学习任务上分别达到67.04％和83.54％。在5次1次射击和5次5次射击任务中，这些分别增加2.22％和1.4％。在其他评估的数据集上，可以观察到SOTA结果相近一致的2-3％的收益。请注意，RFS-蒸馏[41]使用多次迭代（最多3-4代）进行模型蒸馏，而SKD仅使用单代进行蒸馏。我们将收益归因于我们使用知识蒸馏来约束嵌入空间中的变化，同时最小化图像与其旋转对之间的嵌入距离，从而增强了模型的表示能力

**4.2 Ablation Studies and Analysis**

损失函数的选择：我们通过逐步将它们整合到我们提出的方法中来研究不同贡献的影响。为此，我们首先评估有无自我监督损失的方法。如果我们仅用交叉熵损失训练Gen-0，这与RFS简单[41]相同，则该模型在CIFAR-FSand的5次1发任务中达到71.5±0.8％和62.02±0.63％miniImageNet分别。然后，如果我们在额外的自我监督下训练Gen-0，则模型性能将提高到74.5±0.9％和65.93±0.81％。通过合并我们提出的自我监督，这表明绝对收益分别为3.0％和3.91％。此外，如果我们仅对Gen-1进行知识蒸馏，那么可以看到Gen-0的自我监督对下一代产生了明显的影响。如表3所示，Gen-0的自我监督导致Gen-1的性能提高2％。此外，在第1代期间，表3证明了使用L2损失使旋转增强的对数更紧密的优势。我们可以看到，即使对于两个在LceandLce +αLss上训练的Gen-0模型，Gen-期间也增加了L`2损失。与仅使用知识蒸馏相比，图1的增益约为1％。这些经验性评估在我们提出的两阶段方法中清楚地确立了不同贡献的个体重要性（自我监督，知识提炼和确保输出空间中图像的增强版本的接近性）。

自我监督的选择：我们将进一步研究自我监督的不同选择。代替基于旋转的自我监督，我们使用图像的2×2crop，然后训练最终的分类器来预测正确的裁剪象限[39]。表4中的结果表明，基于作物的自我监督方法也可以超越SOTA FSL方法，尽管它的执行效果比轮作要低一些。

![](C:\Users\Administrator\Desktop\day0623\10.png)

表3：CIFAR-FS [3]和FC100 [28]上的FSL结果，具有Gen-0和Gen-1损失函数的不同组合。对于Gen-1，箭头左侧的损失函数用于训练Gen-0模型

![](C:\Users\Administrator\Desktop\day0623\11.png)

表4：在CIFAR-FS [3]和FC100 [28]数据集上的少量学习结果，与无自我监督的对比与寻找旋转并找到补丁的位置作为自我监督方法的比较

![](C:\Users\Administrator\Desktop\day0623\12.png)

图3：损耗系数超参数α和β敏感性的消融研究。

基于自我监督。我们进一步对simCLR损失进行了实验[5]，它的目的还在于使扩增对对与Gen-1期间的知识升华更加紧密。我们的实验表明，simCLR在1次和5次射击任务上仅分别达到75.0±0.8％和88.2±0.6％。

α的变化：在SKD的Gen-0期间，α控制着自我监督对分类的贡献。图3（左）显示了通过改变α的Gen-0性能。我们观察到性能从0到2上升，然后下降。结果表明，性能对α值不敏感。重要的是要注意，没有自我监督的Gen-0（即α= 0）与其他α值相比表现最低，因此确立了自我监督的重要性

β的变化：在Gen-1处，我们再次使用系数β来控制loss  $L_{l2}$超知识蒸馏的贡献。根据图3（右）的结果，我们观察到与α情况相似的趋势，即性能首先在0≤β≤0.1时有所提高，然后随着较大的β值而下降，但是即使将β从0.1更改为0.5，性能仅下降约0.6％。需要注意的是，在CIFAR-FS上，在无$L_{l2}$损失的5次1拍下的性能仅为75.6±0.9％，是与其他β值相比最低的，表明了$L_{l2}$的重要性

时间复杂度让我们假设这是训练一代人所需的时间。RFS [41]的时间复杂度为O（n×T），其中世代数通常为3-4。但是，我们的复杂度是O（2×T）。请注意，在GPU上进行并行计算时，额外的旋转增强不会影响训练时间T 许多。同样，我们通常以比Gen-0少的纪元数训练Gen-1模型。对于第一代在CIFAR-FS上使用单个Tesla V100 GPU，RFS和SKD大约需要相同的时间，即T = 88分钟。RFS在CIFAR-FS上的完整培训时间约为4小时，而SKD仅需2小时

#### 5 Conclusion

深度学习模型可以轻松地适应FSL设置中可用的稀缺数据。为了增强通用性，现有方法对模型进行正则化以保留边距或通过元学习对高级学习行为进行编码。在这项工作中，我们采用了不同的方法，并建议通过自我监督学习来学习真正的输出分类流形。我们的方法分两个阶段进行：首先，模型学习对输入进行分类，以使输出中的多样性不会丢失，从而避免对自然输出歧管结构进行过度拟合和建模。一旦学会了这种结构，我们的方法将训练一个学生模型，该模型保留原始输出流形结构，同时共同最大程度地提高学习表示的可分辨性。我们在四个流行基准上的结果显示了我们的方法的好处，该方法为FSL建立了新的最新技术

**Broader Impact**

这项研究旨在使机器具备仅使用几个示例就可以学习新概念的功能。仅使用几个示例即可开发可以推广到大量对象类的机器学习模型，这将对社会产生积极的影响。例如，使视障人士能够了解他们周围的环境，并增强用于医疗保健和老年人护理设施的机器人的功能。它有可能减少昂贵而费力的数据获取和注释工作，以学习包括图像分类，检索，语言建模和对象检测在内的领域中的模型。但是，我们必须谨慎，少数射击学习技术可能会被专制政府机构滥用，这会损害个人隐私

[代码地址](https://github.com/brjathu/SKD)

第0阶段

1.先确定参数

2.设置可视化

3.数据加载

​		|——数据增强:随机裁剪，颜色抖动，垂直翻转，归一化（训练集），或者什么增强都不做

​					测试集的话，要么随机裁剪，垂直翻转，归一化，或者什么增强都没有

训练集和验证集的区别，验证集是test变换，batch_size是原来的一半，不洗牌，丢掉不足一个batch的部分，num_workers是原来一半

训练模型：

设置：sgd优化器，学习率，交叉熵损失，加载数据

1.数据进行增强：翻转4次，每次旋转90度。然后拼接起来，对应的标签复制4份，同时生成rot标签，每一份一个序号。

2.通过网络得到特征（Resnet12_ssl）：logits=feat, train_logit正常的分类结果。rot_logits分类进一步缩小

3.计算train_logit损失->loss_ce和rot_logits->loss_ss损失。总损失=gamma*loss_ss + loss_ce

4.计算训练的准确率top1，top5

验证集，测试集：

加载验证集，数据变换，计算logit，用LR进行约束，约束完就进行预测，让然后计算准确率

数据增强

第1阶段

加载参数，加载数据，加载第0阶段模型

定义交叉熵损失，kl蒸馏损失，使用sgd优化器，定义学习率

训练模型：

数据增强，旋转一下，旋转1次，每次90°，然后将这些数据进行拼接。

取2次model的data部分，其他的地方和第0阶段差不多

```python
# CIFAR style transformation
mean = [0.5071, 0.4867, 0.4408]
std = [0.2675, 0.2565, 0.2761]
normalize_cifar100 = transforms.Normalize(mean=mean, std=std)
transform_D = [
    transforms.Compose([
        lambda x: Image.fromarray(x),   # 遍历每张图片
        transforms.RandomCrop(32, padding=4),   # 随机裁剪
        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),   #对颜色的数据增强：图像亮度、饱和度、对比度变化
#         transforms.RandomRotation(10),    # 随机旋转-10到10度
        transforms.RandomHorizontalFlip(),  # 垂直翻转，默认是0.5
        lambda x: np.asarray(x),    # 变成np类型
        transforms.ToTensor(),      # 转Tensor类型
        normalize_cifar100      # 归一化
    ]),

    transforms.Compose([
        lambda x: Image.fromarray(x),
        transforms.ToTensor(),
        normalize_cifar100
    ])
]

transform_D_test = [
    transforms.Compose([
        lambda x: Image.fromarray(x),
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        lambda x: np.asarray(x),
        transforms.ToTensor(),
        normalize_cifar100
    ]),

    transforms.Compose([
        lambda x: Image.fromarray(x),
        transforms.ToTensor(),
        normalize_cifar100
    ])
]
```



__ len __ ()这个魔术方法，能给类加一个len方法

np.random.choice(a,size,replace,p)其作用是按要求生成一个一维数组

a是生成一维数组的来源，可以是int类型，可以是数组，也可以是list
size 为从a中抽取的个数，即生成数组的维度
replace 表示从a中是否不重复抽取，默认可重复
p 给出抽取概率，默认随机

### 少样本学习（FSL: Few-shot learning)   
[orgin](https://blog.csdn.net/weixin_37589575/article/details/92801610)

需要这种技术的原因：
1.人类学习不需要大量的训练样本。但是深度学习需要。
2.一些专业的数据集，需要专家进行标记。比如说医学类的数据集。

Few-shot learning 问题的关键是解决过拟合 (overfitting) 的问题，因为训练的样本太少了，训练出的模型可能在训练集上效果还行，但是在测试集上面会遭遇灾难性的崩塌。

#### FSL思路：

**数据增强和正则化**

1.数据增强就是旋转平移等等，让图片变多一点

2.正则化，因为训练样本太少，很容易就过拟合了，所以添加正则项让最后分类的时候多考虑一些。比如说，利用网络从特征中学习到一个embedding，然后用这embedding做分类，如果是FSL，性能会大幅度下滑（准确率70%->40%)要是训练的时候给损失函数加一个正则。将feature到embedding的过程看成是encoder，然后多加几层网络作为decoder，将embedding重构为feature，然后重构误差作为正则项。准确率能够有所提高(准确率40%->50%)

Meta-learning(元学习)

主要分3类：1.学习微调 	2.基于RNN的记忆	3.度量学习

2.基于RNN的记忆：最直观的方法，使用基于 RNN 的技术记忆先前 task 中的表示等，这种表示将有助于学习新的 task。

3.度量学习：核心思想：学习一个 embedding 函数，将输入空间（例如图片）映射到一个新的嵌入空间，在嵌入空间中有一个相似性度量来区分不同类。我们的先验知识就是这个 embedding 函数，在遇到新的 task 的时候，只将需要分类的样本点用这个 embedding 函数映射到嵌入空间里面，使用相似性度量比较进行分类。

